{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "177507ea-111b-4245-9ed7-5fdb5481dca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DataCleaning and FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c8d9d24-3238-4868-8423-0800516b95e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "// PARAMETERS\n",
    "val inputPeriods = dbutils.widgets.get(\"periods\").stripPrefix(\"[\").stripSuffix(\"]\").split(\",\").map(_.trim).toList\n",
    "val skipCleaning = dbutils.widgets.get(\"skip_cleaning\").toBoolean\n",
    "\n",
    "val featureTable = \"silver_layer_yellow_taxi_including_features\"\n",
    "\n",
    "// HELPER FUNCTIONS\n",
    "def loadBronze(period: String): DataFrame = {\n",
    "  val tyear  = period.substring(0,4)\n",
    "  val tmonth = period.substring(5,6)\n",
    "  val tableName = s\"hive_metastore.default.bronze_layer_${tyear}_${tmonth}_yellow_taxi_valid\"\n",
    "  spark.table(tableName)\n",
    "}\n",
    "\n",
    "def removeOutliers(df: DataFrame, colName: String): DataFrame = {\n",
    "  val quantiles = df.stat.approxQuantile(colName, Array(0.25, 0.75), 0.01)\n",
    "  val Q1 = quantiles(0); val Q3 = quantiles(1); val IQR = Q3 - Q1\n",
    "  df.filter(col(colName).between(Q1 - 1.5*IQR, Q3 + 1.5*IQR))\n",
    "}\n",
    "\n",
    "// STEP 0: LOAD DATA FROM BRONZE LAYER\n",
    "val rawDF = inputPeriods.map(loadBronze).reduce(_ unionByName _)\n",
    "\n",
    "rawDF.show(5)\n",
    "\n",
    "\n",
    "// STEP 1: DATA CLEANING (optional)\n",
    "val processedDF: DataFrame = if (!skipCleaning) {\n",
    "  // Deduplicate by key trip identifiers\n",
    "  val dedupedDF = rawDF.dropDuplicates(\n",
    "    \"VendorID\",\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"passenger_count\",\"PULocationID\",\"DOLocationID\"\n",
    "  )\n",
    "\n",
    "  // Basic validity filters\n",
    "  val cleanedDF = dedupedDF\n",
    "    .filter(col(\"fare_amount\") >= 0)\n",
    "    .filter(col(\"trip_distance\") >= 0)\n",
    "    .filter(col(\"passenger_count\") > 0)\n",
    "    .filter(col(\"total_amount\") >= 0)\n",
    "\n",
    "  // Drop rows missing critical fields\n",
    "  val noNullDF = cleanedDF.na.drop(\n",
    "    Seq(\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"fare_amount\",\"trip_distance\",\"total_amount\")\n",
    "  )\n",
    "\n",
    "  // Outlier removal (trip_distance and fare_amount)\n",
    "  val finalCleanDF = removeOutliers(\n",
    "    removeOutliers(noNullDF, \"trip_distance\"),\n",
    "    \"fare_amount\"\n",
    "  )\n",
    "\n",
    "  println(s\"Data Cleaning complete. Records after cleaning: \" + finalCleanDF.count())\n",
    "  finalCleanDF\n",
    "} else {\n",
    "  println(s\"Skipping Data Cleaning. Using raw ingested data.\")\n",
    "  rawDF\n",
    "}\n",
    "\n",
    "// STEP 2: FEATURE ENGINEERING\n",
    "val feDF = processedDF\n",
    "  // Trip duration in minutes\n",
    "  .withColumn(\n",
    "    \"trip_duration_min\", \n",
    "    (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 60.0\n",
    "  )\n",
    "  // Temporal features\n",
    "  .withColumn(\"pickup_hour\", hour(col(\"tpep_pickup_datetime\")))\n",
    "  .withColumn(\"pickup_dayofweek\", date_format(col(\"tpep_pickup_datetime\"), \"E\"))\n",
    "  .withColumn(\"pickup_month\", month(col(\"tpep_pickup_datetime\")))\n",
    "  // Efficiency metrics\n",
    "  .withColumn(\"fare_per_mile\", when(col(\"trip_distance\") > 0, col(\"fare_amount\")/col(\"trip_distance\")))\n",
    "  .withColumn(\"fare_per_min\", when(col(\"trip_duration_min\") > 0, col(\"fare_amount\")/col(\"trip_duration_min\")))\n",
    "  // Optional: revenue components\n",
    "  .withColumn(\"has_tip\", when(col(\"tip_amount\") > 0, 1).otherwise(0))\n",
    "  .withColumn(\"is_airport_trip\", when(col(\"airport_fee\") > 0, 1).otherwise(0))\n",
    "\n",
    "\n",
    "// SAVE FINAL FEATURE DATA\n",
    "feDF.write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"delta\")\n",
    "  .saveAsTable(featureTable)\n",
    "\n",
    "println(s\"Feature Engineering complete. Output table: ${featureTable}\")\n",
    "\n",
    "///val featureTableName = \"featured_customers\"\n",
    "\n",
    "///fs.createFeatureTable(\n",
    "///  name = featureTableName,\n",
    "///  primaryKeys = Seq(\"id\"),      // The unique key(s) for your features\n",
    "///  df = feDF,                     // The DataFrame with features\n",
    "///  description = \"Customer features for ML models\"\n",
    "///)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ac36b22-4098-45e7-9631-0b902f90972a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Feature and Dataset Statistics Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5abc6a4e-ae6d-4565-81cb-e187e14ccab3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Pickup hour counts\n",
    "val hourDF = feDF.groupBy(\"pickup_hour\").count()\n",
    "  .withColumnRenamed(\"count\", \"num_trips\")\n",
    "  .withColumn(\"feature_type\", lit(\"pickup_hour\"))\n",
    "  .withColumn(\"feature_value\", col(\"pickup_hour\").cast(\"string\")) // cast to string\n",
    "\n",
    "// Pickup day of week counts\n",
    "val dayDF = feDF.groupBy(\"pickup_dayofweek\").count()\n",
    "  .withColumnRenamed(\"count\", \"num_trips\")\n",
    "  .withColumn(\"feature_type\", lit(\"pickup_dayofweek\"))\n",
    "  .withColumn(\"feature_value\", col(\"pickup_dayofweek\"))\n",
    "\n",
    "// Pickup month counts\n",
    "val monthDF = feDF.groupBy(\"pickup_month\").count()\n",
    "  .withColumnRenamed(\"count\", \"num_trips\")\n",
    "  .withColumn(\"feature_type\", lit(\"pickup_month\"))\n",
    "  .withColumn(\"feature_value\", col(\"pickup_month\").cast(\"string\"))\n",
    "\n",
    "// Union all into one table\n",
    "val temporalDF = hourDF.select(\"feature_type\", \"feature_value\", \"num_trips\")\n",
    "  .unionByName(dayDF.select(\"feature_type\", \"feature_value\", \"num_trips\"))\n",
    "  .unionByName(monthDF.select(\"feature_type\", \"feature_value\", \"num_trips\"))\n",
    "\n",
    "display(temporalDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abcc237c-f253-42cd-b6d3-c41b31a077e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "// Binary Feature Distributions\n",
    "val binaryCols = Seq(\"has_tip\", \"is_airport_trip\")\n",
    "binaryCols.foreach { c =>\n",
    "  display(feDF.groupBy(c).count())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bca1cd1-7d7a-41c2-ba14-b265428478b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Task2_Cleaning_and_FeatureEngineering",
   "widgets": {
    "periods": {
     "currentValue": "",
     "nuid": "0533f5b2-83bc-4af7-9152-6eaec67de4a2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "202507",
      "label": null,
      "name": "periods",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "202507",
      "label": null,
      "name": "periods",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "skip_cleaning": {
     "currentValue": "false",
     "nuid": "ed2e70f0-96e4-4af9-85d9-3de33e6732af",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": null,
      "name": "skip_cleaning",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "true",
        "false"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "false",
      "label": null,
      "name": "skip_cleaning",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "true",
        "false"
       ]
      }
     }
    }
   }
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
