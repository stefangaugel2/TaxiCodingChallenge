{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a405ab-6c1d-482f-a87c-18dab6e0d17a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import java.net.URL\n",
    "import java.io.File\n",
    "import java.nio.file.{Files, Paths, StandardCopyOption}\n",
    "\n",
    "// -----------------------------\n",
    "// Create a text widget for period\n",
    "// -----------------------------\n",
    "val periodParam = dbutils.widgets.get(\"period\")  // value comes from widget\n",
    "\n",
    "// -----------------------------\n",
    "// Helper: Parse period parameter (YYYYMM)\n",
    "// -----------------------------\n",
    "def parsePeriod(period: String): (Int, Int) = {\n",
    "  require(period.matches(\"\"\"\\d{6}\"\"\"), \"Period must be in format YYYYMM, e.g., 202507\")\n",
    "  val year = period.substring(0, 4).toInt\n",
    "  val month = period.substring(4, 6).toInt\n",
    "  (year, month)\n",
    "}\n",
    "\n",
    "val (tyear, tmonth) = parsePeriod(periodParam)\n",
    "\n",
    "// -----------------------------\n",
    "// Function to download a Parquet file\n",
    "// -----------------------------\n",
    "def downloadTlcMonth(year: Int, month: Int, destFolder: String): Option[String] = {\n",
    "  val filename = f\"yellow_tripdata_$year-$month%02d.parquet\"\n",
    "  val url = s\"https://d37ci6vzurychx.cloudfront.net/trip-data/$filename\"\n",
    "\n",
    "  // Create folder if it does not exist\n",
    "  val folderPath = new File(destFolder)\n",
    "  if (!folderPath.exists()) folderPath.mkdirs()\n",
    "\n",
    "  val destPath = Paths.get(destFolder, filename)\n",
    "  if (Files.exists(destPath)) {\n",
    "    println(s\"File already exists: $destPath\")\n",
    "    return Some(destPath.toString)\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    println(s\"Downloading $filename ...\")\n",
    "    val website = new URL(url)\n",
    "    val in = website.openStream()\n",
    "    Files.copy(in, destPath, StandardCopyOption.REPLACE_EXISTING)\n",
    "    in.close()\n",
    "    println(s\"Download complete: $destPath\")\n",
    "    Some(destPath.toString)\n",
    "  } catch {\n",
    "    case e: Exception =>\n",
    "      println(s\"Failed to download $filename: ${e.getMessage}\")\n",
    "      None\n",
    "  }\n",
    "}\n",
    "\n",
    "// -----------------------------\n",
    "// Download the selected month\n",
    "// -----------------------------\n",
    "val destFolder = \"/dbfs/tmp/yellow\"\n",
    "val filePathOpt = downloadTlcMonth(tyear, tmonth, destFolder)\n",
    "\n",
    "if (filePathOpt.isEmpty) throw new RuntimeException(s\"Failed to download Yellow Taxi data for $tyear-$tmonth\")\n",
    "val filePath = filePathOpt.get\n",
    "\n",
    "// -----------------------------\n",
    "// Convert to Spark DBFS path\n",
    "// -----------------------------\n",
    "val sparkPath = \"dbfs:/\" + filePath.stripPrefix(\"/dbfs/\")\n",
    "\n",
    "// -----------------------------\n",
    "// Read the month into Spark DataFrame\n",
    "// -----------------------------\n",
    "val df_month = spark.read.parquet(sparkPath)\n",
    "\n",
    "println(s\"\\n=== Showing first 10 rows for $tyear-$tmonth%02d ===\")\n",
    "df_month.show(10, truncate=false)\n",
    "();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5128f7a-8565-4177-9ed4-244288a9da2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val yellowTaxiDDL = \"\"\"\n",
    "VendorID INT NOT NULL,                      \n",
    "tpep_pickup_datetime TIMESTAMP NOT NULL,\n",
    "tpep_dropoff_datetime TIMESTAMP NOT NULL,\n",
    "passenger_count BIGINT NOT NULL,\n",
    "trip_distance DOUBLE NOT NULL,\n",
    "RatecodeID BIGINT,\n",
    "store_and_fwd_flag STRING,\n",
    "PULocationID INT,\n",
    "DOLocationID INT ,\n",
    "payment_type BIGINT NOT NULL,\n",
    "fare_amount DOUBLE NOT NULL,\n",
    "extra DOUBLE,\n",
    "mta_tax DOUBLE ,\n",
    "tip_amount DOUBLE ,\n",
    "tolls_amount DOUBLE ,\n",
    "improvement_surcharge DOUBLE ,\n",
    "total_amount DOUBLE NOT NULL,\n",
    "congestion_surcharge DOUBLE ,\n",
    "Airport_fee DOUBLE,\n",
    "cbd_congestion_fee DOUBLE \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import org.apache.spark.sql.types._\n",
    "val yellowTaxiSchema = StructType.fromDDL(yellowTaxiDDL)\n",
    "\n",
    "val fileSchema = spark.read.parquet(sparkPath).schema\n",
    "\n",
    "if (!fileSchema.equals(yellowTaxiSchema)) {\n",
    "  println(s\"Schema mismatch detected for $sparkPath\")\n",
    "  println(\"Expected schema:\")\n",
    "  yellowTaxiSchema.printTreeString()\n",
    "  println(\"File schema:\")\n",
    "  fileSchema.printTreeString()\n",
    "}\n",
    "\n",
    "val df_month_strict = spark.read.option(\"mergeSchema\", \"true\").schema(yellowTaxiSchema).parquet(sparkPath)\n",
    "\n",
    "//df_month_strict.printSchema()\n",
    "//df_month_strict.show(5)\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Add flag columns for each check\n",
    " val df_flagged = df_month_strict\n",
    "  .withColumn(\"invalid_passenger_count\", when($\"passenger_count\" < 1 || $\"passenger_count\" > 6, lit(true)).otherwise(lit(false)))\n",
    "  .withColumn(\"invalid_trip_distance\", when($\"trip_distance\" <= 0, lit(true)).otherwise(lit(false)))\n",
    "  .withColumn(\"invalid_payment_type\", when(!$\"payment_type\".isin(1,2,3,4,5), lit(true)).otherwise(lit(false)))\n",
    "\n",
    "\n",
    "// Show first 10 rows with flags\n",
    "//df_flagged.show(10, truncate=false)\n",
    "\n",
    "// Separate invalid and valid records based on flags\n",
    "val df_quarantine = df_flagged.filter(\n",
    "  $\"invalid_passenger_count\" || $\"invalid_trip_distance\" || $\"invalid_payment_type\"\n",
    ")\n",
    "\n",
    "val df_valid = df_flagged.filter(\n",
    "  !$\"invalid_passenger_count\" && !$\"invalid_trip_distance\" && !$\"invalid_payment_type\"\n",
    ")\n",
    "\n",
    "\n",
    "// Build table names safely\n",
    "val quarantineTable = s\"bronze_layer_${tyear}_${tmonth}_yellow_taxi_quarantine\"\n",
    "val validTable      = s\"bronze_layer_${tyear}_${tmonth}_yellow_taxi_valid\"\n",
    "val df_month_strict_name      = s\"bronze_layer_${tyear}_${tmonth}_yellow_taxi_full\"\n",
    "\n",
    "// Write tables as Delta\n",
    "df_quarantine.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")  // or \"append\" depending on your use case\n",
    "  .saveAsTable(quarantineTable)\n",
    "\n",
    "df_valid.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .saveAsTable(validTable)\n",
    "\n",
    "df_month_strict.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\", \"true\") \n",
    "  .saveAsTable(df_month_strict_name)\n",
    "\n",
    "println(\"âœ… Tables created successfully:\")\n",
    "println(\" - yellow_taxi_valid\")\n",
    "println(\" - yellow_taxi_quarantine\")\n",
    "\n",
    "// Count total records\n",
    "val totalCount = df_flagged.count()\n",
    "\n",
    "// Count quarantined and valid records\n",
    "val quarantineCount = df_quarantine.count()\n",
    "val validCount = df_valid.count()\n",
    "\n",
    "println(s\"Total records: $totalCount\")\n",
    "println(s\"Valid records (non-quarantine): $validCount\")\n",
    "println(s\"Quarantined records: $quarantineCount\")\n",
    "println(f\"Data quality: ${validCount * 100.0 / totalCount}%.2f%% valid\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataIngestion_and_QualityCheck",
   "widgets": {
    "period": {
     "currentValue": "202506",
     "nuid": "07a4315c-b901-4975-bf5a-f93077704a10",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "202507",
      "label": "Period (YYYYMM)",
      "name": "period",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "202507",
      "label": "Period (YYYYMM)",
      "name": "period",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
