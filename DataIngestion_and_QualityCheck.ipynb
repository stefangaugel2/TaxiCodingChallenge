{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a405ab-6c1d-482f-a87c-18dab6e0d17a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import java.net.URL\n",
    "import java.io.File\n",
    "import java.nio.file.{Files, Paths, StandardCopyOption}\n",
    "import java.time.LocalDate\n",
    "import java.time.format.DateTimeFormatter\n",
    "\n",
    "// -----------------------------\n",
    "// Function to download a Parquet file\n",
    "// -----------------------------\n",
    "def downloadTlcMonth(year: Int, month: Int, destFolder: String): Option[String] = {\n",
    "  val filename = f\"yellow_tripdata_$year-$month%02d.parquet\"\n",
    "  val url = s\"https://d37ci6vzurychx.cloudfront.net/trip-data/$filename\"\n",
    "\n",
    "  // Create folder if it does not exist\n",
    "  val folderPath = new File(destFolder)\n",
    "  if (!folderPath.exists()) folderPath.mkdirs()\n",
    "\n",
    "  val destPath = Paths.get(destFolder, filename)\n",
    "  if (Files.exists(destPath)) {\n",
    "    println(s\"File already exists: $destPath\")\n",
    "    return Some(destPath.toString)\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    println(s\"Downloading $filename ...\")\n",
    "    val website = new URL(url)\n",
    "    val in = website.openStream()\n",
    "    Files.copy(in, destPath, StandardCopyOption.REPLACE_EXISTING)\n",
    "    in.close()\n",
    "    println(s\"Download complete: $destPath\")\n",
    "    Some(destPath.toString)\n",
    "  } catch {\n",
    "    case e: Exception =>\n",
    "      println(s\"Failed to download $filename: ${e.getMessage}\")\n",
    "      None\n",
    "  }\n",
    "}\n",
    "\n",
    "// -----------------------------\n",
    "// Determine the most recent month (2 months ago)\n",
    "// -----------------------------\n",
    "val today = LocalDate.now()\n",
    "val previousMonth = today.minusMonths(2)\n",
    "val tyear = previousMonth.getYear\n",
    "val tmonth = previousMonth.getMonthValue\n",
    "\n",
    "// -----------------------------\n",
    "// Download only the most recent available month\n",
    "// -----------------------------\n",
    "val destFolder = \"/dbfs/tmp/yellow\"\n",
    "val filePathOpt = downloadTlcMonth(tyear, tmonth, destFolder)\n",
    "\n",
    "if (filePathOpt.isEmpty) throw new RuntimeException(s\"Failed to download Yellow Taxi data for $tyear-$tmonth\")\n",
    "val filePath = filePathOpt.get\n",
    "\n",
    "// -----------------------------\n",
    "// Convert to Spark DBFS path\n",
    "// -----------------------------\n",
    "val sparkPath = \"dbfs:/\" + filePath.stripPrefix(\"/dbfs/\")\n",
    "\n",
    "// -----------------------------\n",
    "// Read the month into Spark DataFrame\n",
    "// -----------------------------\n",
    "val df_month = spark.read.parquet(sparkPath)\n",
    "\n",
    "println(s\"\\n=== Showing first 10 rows for $tyear-$tmonth%02d ===\")\n",
    "df_month.show(10, truncate=false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5128f7a-8565-4177-9ed4-244288a9da2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val yellowTaxiDDL = \"\"\"\n",
    "VendorID INT NOT NULL,                      \n",
    "tpep_pickup_datetime TIMESTAMP NOT NULL,\n",
    "tpep_dropoff_datetime TIMESTAMP NOT NULL,\n",
    "passenger_count BIGINT NOT NULL,\n",
    "trip_distance DOUBLE NOT NULL,\n",
    "RatecodeID BIGINT,\n",
    "store_and_fwd_flag STRING,\n",
    "PULocationID INT,\n",
    "DOLocationID INT ,\n",
    "payment_type BIGINT NOT NULL,\n",
    "fare_amount DOUBLE NOT NULL,\n",
    "extra DOUBLE,\n",
    "mta_tax DOUBLE ,\n",
    "tip_amount DOUBLE ,\n",
    "tolls_amount DOUBLE ,\n",
    "improvement_surcharge DOUBLE ,\n",
    "total_amount DOUBLE NOT NULL,\n",
    "congestion_surcharge DOUBLE ,\n",
    "Airport_fee DOUBLE,\n",
    "cbd_congestion_fee DOUBLE \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import org.apache.spark.sql.types._\n",
    "val yellowTaxiSchema = StructType.fromDDL(yellowTaxiDDL)\n",
    "\n",
    "val fileSchema = spark.read.parquet(sparkPath).schema\n",
    "\n",
    "if (!fileSchema.equals(yellowTaxiSchema)) {\n",
    "  println(s\"Schema mismatch detected for $sparkPath\")\n",
    "  println(\"Expected schema:\")\n",
    "  yellowTaxiSchema.printTreeString()\n",
    "  println(\"File schema:\")\n",
    "  fileSchema.printTreeString()\n",
    "}\n",
    "\n",
    "val df_month_strict = spark.read.option(\"mergeSchema\", \"true\").schema(yellowTaxiSchema).parquet(sparkPath)\n",
    "\n",
    "//df_month_strict.printSchema()\n",
    "//df_month_strict.show(5)\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Add flag columns for each check\n",
    " val df_flagged = df_month_strict\n",
    "  .withColumn(\"invalid_passenger_count\", when($\"passenger_count\" < 1 || $\"passenger_count\" > 6, lit(true)).otherwise(lit(false)))\n",
    "  .withColumn(\"invalid_trip_distance\", when($\"trip_distance\" <= 0, lit(true)).otherwise(lit(false)))\n",
    "  .withColumn(\"invalid_payment_type\", when(!$\"payment_type\".isin(1,2,3,4,5), lit(true)).otherwise(lit(false)))\n",
    "\n",
    "\n",
    "// Show first 10 rows with flags\n",
    "//df_flagged.show(10, truncate=false)\n",
    "\n",
    "// Separate invalid and valid records based on flags\n",
    "val df_quarantine = df_flagged.filter(\n",
    "  $\"invalid_passenger_count\" || $\"invalid_trip_distance\" || $\"invalid_payment_type\"\n",
    ")\n",
    "\n",
    "val df_valid = df_flagged.filter(\n",
    "  !$\"invalid_passenger_count\" && !$\"invalid_trip_distance\" && !$\"invalid_payment_type\"\n",
    ")\n",
    "\n",
    "\n",
    "// Build table names safely\n",
    "val quarantineTable = s\"bronze_layer_${tyear}_${tmonth}_yellow_taxi_quarantine\"\n",
    "val validTable      = s\"bronze_layer_${tyear}_${tmonth}_yellow_taxi_valid\"\n",
    "val df_month_strict_name      = s\"bronze_layer_${tyear}_${tmonth}_yellow_taxi_full\"\n",
    "\n",
    "// Write tables as Delta\n",
    "df_quarantine.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")  // or \"append\" depending on your use case\n",
    "  .saveAsTable(quarantineTable)\n",
    "\n",
    "df_valid.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .saveAsTable(validTable)\n",
    "\n",
    "df_month_strict.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\", \"true\") \n",
    "  .saveAsTable(df_month_strict_name)\n",
    "\n",
    "println(\"âœ… Tables created successfully:\")\n",
    "println(\" - yellow_taxi_valid\")\n",
    "println(\" - yellow_taxi_quarantine\")\n",
    "\n",
    "// Count total records\n",
    "val totalCount = df_flagged.count()\n",
    "\n",
    "// Count quarantined and valid records\n",
    "val quarantineCount = df_quarantine.count()\n",
    "val validCount = df_valid.count()\n",
    "\n",
    "println(s\"Total records: $totalCount\")\n",
    "println(s\"Valid records (non-quarantine): $validCount\")\n",
    "println(s\"Quarantined records: $quarantineCount\")\n",
    "println(f\"Data quality: ${validCount * 100.0 / totalCount}%.2f%% valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b95d94f6-3d75-462d-a4ea-be8c5e18897b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import yaml \n",
    "from databricks.labs.dqx import check_funcs\n",
    "\n",
    "from databricks.labs.dqx.config import InputConfig, OutputConfig\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.labs.dqx.rule import DQRowRule\n",
    "\n",
    "checks = yaml.safe_load(\"\"\"\n",
    "- name: trip_distance_positive\n",
    "  criticality: error\n",
    "  check:\n",
    "    function: sql_expression\n",
    "    arguments:\n",
    "      expression: \"trip_distance > 0\"\n",
    "\n",
    "- name: passenger_count_valid\n",
    "  criticality: error\n",
    "  check:\n",
    "    function: sql_expression\n",
    "    arguments:\n",
    "      expression: \"passenger_count >= 1 and passenger_count <= 6\"\n",
    "\n",
    "- name: payment_type_allowed\n",
    "  criticality: error\n",
    "  check:\n",
    "    function: is_in_list\n",
    "    arguments:\n",
    "      column: payment_type\n",
    "      allowed:\n",
    "        - 1\n",
    "        - 2\n",
    "        - 3\n",
    "        - 4\n",
    "        - 5\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# Initialize DQEngine\n",
    "dq_engine = DQEngine(WorkspaceClient())\n",
    "status = DQEngine.validate_checks(checks)\n",
    "print(status)\n",
    "\n",
    "\n",
    "# Apply checks in-memory\n",
    "valid_df, invalid_df = dq_engine.apply_checks_and_split(df_month, checks)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataIngestion_and_QualityCheck",
   "widgets": {}
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
